- ---
  title: 算法之散列表
  date: 2019-08-30 19:47:40
  keywords: 跳表
  description: 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。
  categories: 
    - 算法
  tags:
    - 散列表
  comments: false
  ---


# 散列思想

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

**<u>散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是O(1)的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</u>**

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08301409.png)

# 散列函数

<u>**散列函数，顾名思义，它是一个函数。我们可以把它定义成hash(key)，其中key表示元素的键值，hash(key)的值表示经过散列函数计算得到的散列值。**</u>

散列函数设计的基本要求:
1. 散列函数计算得到的散列值是一个非负整数;
2. 如果key1 = key2，那hash(key1) == hash(key2);
3. 如果key1 ≠ key2，那hash(key1) ≠ hash(key2)。

第三点会出现散列冲突。

# 散列冲突

常见的解决散列冲突的方法：

- 开放寻址法（Open addressing)
- 链表法(Chaining)

## **开放寻址法**

**核心思想：如果出现了冲突，我们重新探测一个空闲位置，将其插入。**

- **线性探测**（Linear Probing）：当我们往散列表中插入数据时，如果某个数据经过经过散列函数计算后的存储位置被占用，我们就从当前位置开始，依次往后查找，看时候有空余位置，直到找到为止。

### 插入过程

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311248.png)

> 途中黄色是空闲位置，橙色是被占用的位置，上图计算出x值的下标为7,但是被占用了产生冲突，因此我们依次往下找。

### 查找过程

我们通过散列函数求出要查找元素的**键值对应的散列值**，然后比较数组中下标为散列值的元素和要查找的元
素。如果相等，则说明就是我们要找的元素;否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311349.png)

**y值不在散列表中**

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311350.png)

### 删除操作

我们不能单纯地把要删除的元素设置为空。因为在查找的时候，一旦我们通过线性探测方法，找到一个空闲位置，我们就可以认定散列表中不存在这个数据。但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效。

<u>**我们可以将删除的元素，特殊标记为deleted。当线性探测查找的时候，遇到标记为deleted的空间，并不是停下来，而是继续往下探测。**</u>

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311357.png)

### 缺陷

<u>线性探测法其实存在很大问题。当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为O(n)。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。</u>

### 改进

- 二次探测：

  跟线性探测很像，线性探测每次探测的步长是1，那它探测的下标序列就是hash(key)+0，hash(key)+1，hash(key)+2......而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是hash(key)+0，hash(key)+1^2，hash(key)+2^2......

- 双重散列：

  意思就是不仅要使用一个散列函数。我们使用一组散列函数hash1(key)，hash2(key)，hash3(key)......我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

- 装载因子：

  用装载因子(load factor)来表示空位的多少。装载因子的计算公式是: 

  `散列表的装载因子=填入表中的元素个数/散列表的长度` 

  装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。 



## **链表法**

**链表法是一种更加常用的散列冲突解决办法，在散列表中，每个“桶(bucket)”或者“槽(slot)”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。**

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311410.png)

> - 插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是O(1)。
> - 当查找、删除一个元素时，我们 同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。那查找或删除操作的时间复杂度是多少呢?
> - 实际上，这两个操作的时间复杂度跟链表的长度k成正比，也就是O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中n表示散列中数据的个 数，m表示散列表中“槽”的个数。 



# 工业级散列表

散列表的查询效率并不能笼统地说成是O(1)。它跟散列函数、装载因子、散列冲突等都有关系。

## 如何设计散列函数

- 散列函数不能太复杂，复杂的散列函数计算会耗费很多的时间
- 散列函数生成的值尽可能随机且均匀分布，这样可以尽量避免冲突。

散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等。

## 装载因子过大

**装载因子越大，说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。**

动态散列表来说，数据集合是频繁变动的，我们事先无法预估将要加入的数据个数，所以我们也无法事先申请一个足够大的散列表，当装载因子大到一定程度之后，散列冲突就会变得不可接受。这个时候，我们该如何处理呢？

### 动态扩容

- 当装载因子过大时，重新申请一个原来散列表大小两倍的空间的散列表；
- 散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311538.png)

> 在原来的散列表中，21这个元素原来存储在下标为0的位置，搬移到新的散列表中，存储在下标为7的位置。

### 高效的扩容

为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。

#### 插入数据

当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。

#### 查询数据

对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/08311543.png)



## 解决散列冲突

### 开放寻址法

**优点**：

- 数据都在数组中，可以有效的利用CPU缓存
- 序列化比较方便

**缺点**：

- 用开放寻址方式解决冲突的散列表，删除数据比较麻烦，需要标记已经删除的数据。

**当数据量比较小，装载因子小的时候，适合采用开放寻址法。比如JAVA的ThreadLocalmap**

### 链表法

**优点：**

- 对内存的利用效率比开放寻址高
- 对装载因子的容忍度更高，开放寻址只能适合装载因子小于1的情况，链表法只要散列函数的值随机均匀，变成10也可以。

**缺点：**

- 对于小对象存储，相对比较耗内存
- 链表结点分散，对于CPU缓存不友好，这方面的执行效率有一定的影响。

**链表法比较适合较大存储对象，大量数据的散列表，比起开放寻址法，更加灵活，支持更多的优化策略**

## Java的HashMap

- 初始大小

  HashMap默认初始化大小为16，当然这个默认值可以设置，如果事先知道数据有多大，就可以大大提高Hashmap性能

- 装载因子和动态扩容

  最大装载因子默认是0.75.当HashMap中元素超过0.75*capacity。就会启动扩容，每次扩容为原来的两倍。

- 散列冲突解决办法

  JDK1.8中，当链表长度超过默认的8时，链表就转换为红黑树。因为红黑树可以提高增删改查，提高HashMap的性能。当红黑树结点少于8个时，又将红黑树转化为链表

- 散列函数

  ```java
  int hash(Object key) {
    int h = key.hashCode();
    return (h^(h>>>16))&(capacity-1);
  }
  //其中Hashcode返回的是java对象的hash code,下面是String类型对象的HashCode
  
  public int hashCode() {
    int var1 = this.hash;
    if (var1 == 0 && this.value.length > 0) {
      char[] var2 = this.value;
      for (int var3 = 0; var3 < this.value.length, ++var3) {
        var1 = 31*var1 + var2[var3];
      }
      this.hash = var1;
    }
    return var1;
  }
  ```

  

## 总结

工业级的散列表应该具有哪些特性?

- 支持快速的查询、插入、删除操作;
- 内存占用合理，不能浪费过多的内存空间;
- 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。

如何实现这样一个散列表呢?根据前面讲到的知识，我会从这三个方面来考虑设计思路:

- 设计一个合适的散列函数;
-  定义装载因子阈值，并且设计动态扩容策略
-  选择合适的散列冲突解决方法。

# 散列表和链表应用

## **LRU**缓存淘汰算法

使用链表实现的LRU:当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部;如果找到了，我们就把它移动到链表的尾部。因为查找数据需要遍历链表，所以单纯用链表实现的LRU缓存淘汰算法的时间复杂很高，是O(n)。

**优化：**

可以使用散列表和链表结合将LRU时间复杂度降低为O(1).

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/09011728.png)

> - 每个单独的结点有 `prev`/`next`和 `hnext`指针
> - 散列表通过链表解决冲突,有两个拉链：1/是默认的双向链表，另一个是散列表中的拉链；prev和next是为了实现将结点穿在双向链表中，2/hnext指针是为了将结点串在散列表的拉链中

### 查找过程

散列表中根据散列函数查找的复杂度是O(1),查找到之后，需要将它移动到链表尾部。

### 删除过程

删除我们需要查找数据，我们可以再O(1)内找到元素，由于是双向链表，所以删除操作也是O(1);

### 添加过程

- 首先查看数据是否在缓存中，如果在，需要将其移动到双向链表的尾部；
- 如果不在，需要看缓存是否已满；如果满了，则将双向链表头部删除，然后将数据放到链表尾部；没有满，则直接放到链表尾部。

## **Redis**有序集合

在跳表有序集合中，每个成员对象有两个重要属性，key和score。我么不仅可以通过key查找，还可能通过score查找。

举个例子，比如用户积分排行榜有这样一个功能:我们可以通过用户的ID来查找积分信息，也可以通过积分区间来查找用户ID或者姓名信息。这里包含ID、姓名 

和积分的用户信息，就是成员对象，用户ID就是key，积分就是score。 所以，如果我们细化一下Redis有序集合的操作，那就是下面这样: 

- 添加一个成员对象;
-  按照键值来删除一个成员对象;
-  按照键值来查找一个成员对象;
-  按照分值区间查找数据，比如查找积分在[100, 356]之间的成员对象; 
- 按照分值从小到大排序成员变量; 

如果我们仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢，解决方法与LRU缓存淘汰算法的解决方法类似。我们可以再 按照键值构建一个散列表，这样按照key来删除、查找一个成员对象的时间复杂度就变成了O(1)。同时，借助跳表结构，其他操作也非常高效。 



## Java LinkedHashMap

**LinkedHashMap是通过双向链表和散列表这两种数据结构组合实现的。LinkedHashMap中的“Linked”实际上是指的是双向链表，并非指用链表法解决散列冲突。**

**LinkedHashMap也是通过散列表和链表组合在一起实现的。实际上，它不仅支持按照插入顺序遍历数据，还**

**支持按照访问顺序来遍历数据**。



按照访问时间排序的LinkedHashMap本身就是一个支持LRU缓存淘汰策略的缓存系统?实际上，它们两个的实现原理也是一模一样的。

我们先来看一段代码。你觉得这段代码会以什么样的顺序打印3，1，5，2这几个key呢?原因又是什么呢?

```java
HashMap<Integer, Integer> m = new LinkedHashMap<>(); m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);
for (Map.Entry e : m.entrySet()) { 
	System.out.println(e.getKey());	
}
```

上面的代码会按照数据插入的顺序依次来打印，也就是说，打印的顺序就是3，1，5，2。你有没有觉得奇怪?散列表中数据是经过散列函数打乱之后无规律存储的，这里是如何实现按照数据的插入顺序来遍历打印的呢?



**例子：**

```java
// 10是初始大小，0.75是装载因子，true是表示按照访问时间排序 HashMap<Integer, Integer> m = new LinkedHashMap<>(10, 0.75f, true); m.put(3, 11);
m.put(1, 12);
m.put(5, 23); 
m.put(2, 22);
m.put(3, 26); 
m.get(5);
for (Map.Entry e : m.entrySet()) { 
  System.out.println(e.getKey());
}
```

每次调用put()函数，往LinkedHashMap中添加数据的时候，都会将数据添加到链表的尾部，所以，在前四个操作完成之后，链表中的数据是下面这样:

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/09011835.png)

在第8行代码中，再次将键值为3的数据放入到LinkedHashMap的时候，会先查找这个键值是否已经有了，然后，再将已经存在的(3,11)删除，并且将新的(3,26)放到链表的尾部。所以，这个时候链表中的数据就是下面这样:

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/09011836.png)

当第9行代码访问到key为5的数据的时候，我们将被访问到的数据移动到链表的尾部。所以，第9行代码之后，链表中的数据是下面这样:

![image](https://raw.githubusercontent.com/HaviLee/Blog-Images/master/高手/09011837.png)

所以，最后打印出来的数据是1，2，3，5.

# 面试题

Word文档中单词拼写检查功能是如何实现的?

> 常用的英文单词有20万个左右，假设单词的平均长度是10个字母，平均一个单词占用10个字节的内存空间，那20万英文单词大约占2MB的存储空间，就算放 大10倍也就是20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。所以我们可以用散列表来存储整个英文单词词典。 当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确;如果没有查到，则说明拼写可能有误，给予提示。借助散列 表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误。